# Newsletter: The Friction That Was Protecting You

---
status: draft
created_date: 2026-02-27
topic: AI Hyper-Achievers Burnout
platform: newsletter
source_article: article-ai-hyperachievers-burnout-no-limits-2026-02-27.md
published: false
---

## SUBJECT LINE OPTIONS

**Primary:**
The friction that was actually protecting you

**Variant B:**
Why AI is burning out its biggest fans first

**Variant C:**
I thought more capacity would fix everything

Notes: Primary uses the counterintuitive reframe -- "friction" as protection, not obstacle. Variant B targets the surprising who (enthusiasts, not resisters) to create a curiosity gap. Variant C leads with personal fallibility in the Veritasium style. All avoid spam triggers and stay within 45 characters.

---

## PREVIEW TEXT

The first people burning out aren't who you'd expect...

Notes: Complements all three subject lines by hinting at the surprising reversal without repeating the subject. The ellipsis invites the reader to open for the full picture. Avoids giving away the punchline.

---

## EMAIL BODY

---

I used to think hyper-achievers had one real problem: not enough capacity to match their ambition.

Too many ideas, not enough hours. Too much vision, not enough bandwidth. If only they could move faster, think bigger, ship more.

Then AI arrived. The capacity to match the ambition. Finally, no ceiling.

Here's what I expected to happen: the most ambitious people would thrive like never before.

Here's what actually happened: they burned out first.

---

### The data that stopped me

Not the reluctant adopters. Not the skeptics dragging their feet. The *enthusiasts*.

88% of the highest-productivity AI users report burnout. Frequent AI users show 45% higher burnout rates than infrequent users. And 77% of employees say AI has *added* to their workload, not reduced it.

That last number is the one I keep coming back to. A tool designed to reduce work is increasing it -- and the people it's increasing it for the most are the ones using it most enthusiastically.

A UC Berkeley study published last month found the mechanism: workers voluntarily extended their hours without being asked, expanding into tasks they'd previously outsourced or skipped entirely. The researchers put it plainly: "You don't work less. You just work the same amount or even more."

Nobody forced them. They chose it. Because they could.

---

### An economist from 1865 explains why

William Stanley Jevons noticed something counterintuitive about steam engines. When engines became more efficient and used less coal per unit of work, total coal consumption went *up*, not down.

Why? Because cheaper energy made coal viable for applications nobody had considered before. Efficiency didn't reduce usage. It expanded the territory.

AI is doing this to human attention right now.

When it takes 20 minutes to write a report instead of 3 hours, you don't bank the 2 hours and 40 minutes. You write five more reports. When you can generate a week's worth of content in an afternoon, you don't take Friday off. You start a second content stream.

The ceiling was never really a ceiling. It was a constraint that forced prioritization, rest, and recalibration. It was the mechanism by which the signal "you've done enough" reached ambitious people.

AI removed that signal.

---

### Protective friction

Here's the reframe that changed how I think about this:

The friction AI removes is not purely inefficiency. Some of it is protection.

A University of Toronto study from earlier this year put it in terms that stuck with me: "The very friction AI removes -- the effort, struggle, and difficulty essential to human growth -- may be critical for psychological well-being."

Think about what constraints used to do for us. You couldn't take on every project because you only had so many hours. You couldn't chase every idea because execution was slow. You had to choose. And in choosing, you rested from the things you didn't pick.

AI didn't give hyper-achievers more time. It gave them more capacity. Those are not the same thing.

More time means space to breathe. More capacity means more surface area for ambition to fill.

---

### This isn't theoretical

Last week, Hieu Pham -- former OpenAI technical staff, previously at xAI and Google Brain -- resigned citing burnout. What made his statement remarkable was this line: "All the mental health deteriorating that I used to scoff at is real, miserable, scary, and dangerous."

He used to scoff at it. He was the enthusiast. The hyper-achiever. The person who would have said "I'm built different" -- right up until he wasn't.

Meanwhile, Cognition AI requires 80-hour weeks and explicitly rejects work-life balance. Their flagship product, Devin, ranked among the least-adopted AI tools in the industry.

The WHO and ILO data is sobering: 55+ hour weeks correlate with 35% higher stroke risk and 17% higher heart disease mortality. Deaths from long-hours heart disease rose 42% between 2000 and 2016. That was before AI made it possible to be productive around the clock.

---

### The question I'm sitting with

Oliver Burkeman calls it the "Kaiser Reward": the reward for efficiency is more work. AI amplifies this dynamic to a scale we've never seen.

His insight keeps echoing: "The more you try to manage your time with the goal of achieving total control and freedom from the inevitable constraints of being human, the more stressful, empty, and frustrating life gets."

The most productive thing a hyper-achiever might do right now is not find a better AI workflow. It might be figuring out what "enough" looks like -- and actually stopping there.

I don't say that prescriptively. I'm genuinely wrestling with it myself. Because the friction that used to slow me down? I'm starting to think some of it was holding me together.

---

**Here's what I'm curious about: have you noticed yourself doing *more* since you started using AI tools, not less? And if so -- does it feel like progress or like something else?**

Hit reply. I read every response.

---

Talk soon,

[Your sign-off]

P.S. The full article digs deeper into the Jevons Paradox, the research on protective friction, and the cultural dynamics at companies pushing extreme hours. If the "friction as protection" idea resonates, the complete version is worth the read.

[Read the full article]

---

## TECHNICAL SPECS

- **Total word count:** ~830 words
- **Estimated read time:** 3.5 minutes
- **Primary CTA:** Reply with personal experience on whether AI has increased or reduced workload
- **Secondary CTA:** Read the full article
- **Spam score indicators:** Low risk. No trigger words, no excessive punctuation, no sales language. Conversational tone throughout. Statistics are contextual, not promotional.

---

## ENGAGEMENT STRATEGY

- **Best send time:** Wednesday or Thursday, 7-9 AM local time (midweek reflection point when workload pressure is most felt)
- **Expected open rate:** 38-48% (subject line reframes a universally positive concept -- "removing friction" -- as potentially dangerous, which creates strong curiosity)
- **Expected reply rate:** 5-8% (closing question asks about personal experience with a low barrier -- "have you noticed this?" -- rather than asking for analysis or opinion)
- **Follow-up plan:** Could connect to future content on defining "enough" in an age of infinite capacity, the difference between productivity and output, or how constraints drive creativity

---

## A/B TEST VARIANTS

**Subject line variants:**
- A: "The friction that was actually protecting you"
- B: "Why AI is burning out its biggest fans first"
- C: "I thought more capacity would fix everything"

**Preview text variants:**
- A: "The first people burning out aren't who you'd expect..."
- B: "88% of the highest-productivity AI users report burnout."

**CTA variants:**
- A: Reply question about personal AI workload experience (primary -- lower barrier)
- B: "What does 'enough' look like for you right now?" (higher vulnerability, potentially deeper responses but fewer)

---

## SELF-VERIFICATION CHECKLIST

- [x] Subject line creates curiosity without clickbait
- [x] Preview text adds value, doesn't repeat subject
- [x] Opening hook works within 3 seconds (personal assumption immediately challenged)
- [x] Voice matches examples from writing-examples.md (myth-busting opening, personal fallibility, evidence pivot, discovery framing)
- [x] Paragraphs are 2-3 sentences maximum
- [x] Value is clear and actionable (reframes AI productivity from "how to do more" to "how to recognize protective limits")
- [x] Single, clear CTA included (reply with personal observation)
- [x] Mobile formatting verified (short paragraphs, scannable sections, clear hierarchy)
- [x] No spam trigger words used
- [x] Personal element included ("surprised me," "I keep coming back to," "changed how I think," "wrestling with it myself")
- [x] Read time under 4 minutes

---

## NOTES

**Key adaptations from article:**
- Condensed from full article to ~830 words while preserving the core narrative arc
- Preserved the Jevons Paradox as the central explanatory mechanism -- it's the most memorable and shareable concept
- Kept the strongest data points: 88% burnout, 45% higher rates, 77% added workload, UC Berkeley finding
- Retained the Hieu Pham case study as the visceral human example -- his self-awareness about previously scoffing at burnout is the emotional turning point
- Cut the detailed WHO/ILO statistics to a single paragraph for impact without data overload
- Ends with genuine uncertainty rather than prescriptive advice, matching the voice guidelines

**Voice alignment:**
- Opens with "I used to think" (matches the personal fallibility pattern from writing-examples.md: "I used to think networking was about meeting new people. I was wrong.")
- Challenges the dominant narrative (AI as liberator) without dismissing AI itself
- Discovery-oriented framing: "stopped me," "I keep coming back to," "changed how I think," "I'm genuinely wrestling with it"
- The Burkeman section serves as the philosophical grounding without becoming preachy
- Closing question is genuinely curious, not rhetorical -- asks readers to examine their own experience
- Maintains the Veritasium approach: addresses what people think they know (AI removes friction = good), then reveals the surprising truth (some friction was protective)

**What this newsletter preserves from the article:**
- The counterintuitive reversal: enthusiasts burning out before skeptics
- Jevons Paradox as the explanatory framework
- The distinction between more time and more capacity
- University of Toronto's "protective friction" finding
- Hieu Pham as the human case study
- Burkeman's philosophical framing
- The closing insight: friction was holding you together

**What this newsletter intentionally cuts:**
- Cognition AI culture details beyond a single paragraph (too negative/judgmental for the voice)
- Detailed WHO/ILO mortality statistics (kept one line for gravity, cut the rest)
- Extended Burkeman "Kaiser Reward" analysis
- The article's more directive conclusion -- replaced with genuine uncertainty to match voice guidelines
- Multiple statistical citations condensed to the most impactful numbers
- The "extreme culture not working" section reduced to a brief contrast point

These cuts keep the newsletter focused on the single insight (friction as protection, not obstacle) while the full article provides the complete evidence base and cultural analysis.
